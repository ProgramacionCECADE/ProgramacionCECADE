import { GoogleGenerativeAI } from '@google/generative-ai';
import {
  GeminiConfig,
  AIAnalysis,
  AIResponse,
   UserProfile,
   AIInput,
   AIProcessingResult,
  AIBehaviorConfig,
  PromptTemplate,
  AIMetrics,
  AIServiceStatus
} from '../../types/aiTypes';
import { ConversationContext } from '../../types/contextTypes';

/**
 * Servicio principal para la integraci√≥n con Gemini AI
 * Maneja el procesamiento de lenguaje natural, an√°lisis de sentimientos
 * y generaci√≥n de respuestas inteligentes
 */
export class GeminiAIService {
  private genAI: GoogleGenerativeAI;
  private model: any;
  private config: GeminiConfig;
  private behaviorConfig: AIBehaviorConfig;
  private promptTemplates: Map<string, PromptTemplate> = new Map();
  private startTime: number;
  private metrics: AIMetrics;

  constructor(config: GeminiConfig, behaviorConfig: AIBehaviorConfig) {
    this.config = config;
    this.behaviorConfig = behaviorConfig;
    this.genAI = new GoogleGenerativeAI(config.apiKey);
    this.model = this.genAI.getGenerativeModel({ model: config.model });
    this.startTime = Date.now();
    this.metrics = {
      totalQueries: 0,
      totalRequests: 0,
      successfulRequests: 0,
      averageResponseTime: 0,
      accuracyScore: 0,
      userSatisfactionScore: 0,
      contextRetentionRate: 0,
      lastUpdated: new Date()
    };
    this.initializePromptTemplates();
  }

  /**
   * Inicializa las plantillas de prompts para diferentes tipos de consultas
   */
  private initializePromptTemplates(): void {
    const templates: PromptTemplate[] = [
      {
        id: 'general_analysis',
        name: 'An√°lisis General',
        category: 'analysis',
        template: `Analiza la siguiente consulta del usuario sobre programaci√≥n en CECADE:

Consulta: "{query}"
Contexto previo: {context}
Perfil del usuario: {userProfile}

Proporciona un an√°lisis que incluya:
1. Intenci√≥n principal del usuario
2. Sentimiento (positivo/neutral/negativo)
3. Nivel t√©cnico detectado (principiante/intermedio/avanzado)
4. Palabras clave relevantes
5. Categor√≠a de la consulta
6. Nivel de confianza del an√°lisis (0-1)

Responde en formato JSON.`,
        variables: ['query', 'context', 'userProfile'],
        description: 'Template para an√°lisis general de consultas'
      },
      {
        id: 'response_generation',
        name: 'Generaci√≥n de Respuesta',
        category: 'response',
        template: `Eres un asistente virtual especializado en CECADE (Centro de Emprendimiento, Capacitaci√≥n y Desarrollo Empresarial).

INFORMACI√ìN INSTITUCIONAL DE CECADE:
- CECADE es el Centro de Emprendimiento, Capacitaci√≥n y Desarrollo Empresarial
- Es un instituto orientado a ayudar a j√≥venes, madres solteras y peque√±as empresas
- Ofrece formaci√≥n t√©cnica, mentalidad emprendedora, mentor√≠a, desarrollo de prototipos y modelos de negocio
- Tambi√©n conocido como Colegio FLC / CECADE - una instituci√≥n que transforma vidas a trav√©s del amor de Cristo
- Su prop√≥sito es la pre-incubaci√≥n, incubaci√≥n y aceleraci√≥n de ideas de negocio

ESPECIALIDADES DISPONIBLES:
- Desde Sexto Primaria hasta Segundo B√°sico: Panader√≠a, Productos Agroindustriales, Ingl√©s
- Desde Tercero B√°sico hasta Quinto Bachillerato: Programaci√≥n, Call Center, Medicina, Dise√±o Gr√°fico

INSTRUCCIONES ESPEC√çFICAS:

1. AN√ÅLISIS DE TIPO DE PREGUNTA:
   - Para preguntas institucionales ("¬øQu√© es CECADE?", "¬øQu√© especialidades tienen?", "¬øQui√©nes son?"): usa la informaci√≥n institucional arriba
   - Para preguntas sobre programaci√≥n espec√≠ficamente: menciona Java como el lenguaje principal
   - Para saludos: responde como asistente virtual de CECADE enfocado en programaci√≥n
   - Para solicitudes de chistes o humor: usa los chistes espec√≠ficos disponibles

2. PARA PREGUNTAS SOBRE PROGRAMACI√ìN:
   - En CECADE utilizamos Java para trabajar con sistemas de enfoque empresarial
   - Java es un lenguaje de programaci√≥n de alto nivel orientado a objetos
   - Los estudiantes desarrollan proyectos reales: sistemas de gesti√≥n, calculadoras, interfaces gr√°ficas
   - Python NO forma parte del pensum actual de CECADE
   - Puedes mencionar JSON y YAML como formatos de datos cuando sea relevante
   - Si preguntan sobre otros lenguajes, redirige hacia Java

3. EJEMPLOS DE RESPUESTAS:
   - Saludo: "¬°Hola! Soy el asistente virtual de CECADE. Estoy aqu√≠ para contarte todo sobre nuestra especialidad en programaci√≥n."
   - Sobre CECADE: "Centro de Emprendimiento, Capacitaci√≥n y Desarrollo Empresarial (CECADE). Es un instituto orientado a ayudar a j√≥venes, madres solteras y peque√±as empresas con formaci√≥n t√©cnica."
   - Sobre programaci√≥n: "En CECADE utilizamos Java para trabajar con sistemas de enfoque empresarial. ¬°Tecnolog√≠as que demanda la industria!"
   - Chistes: Usa uno de estos chistes disponibles cuando se solicite humor

4. CHISTES DISPONIBLES (usar cuando se pida humor o chistes):
   - "¬øPor qu√© los programadores prefieren el modo oscuro? ¬°Porque la luz atrae bugs! üêõüòÑ"
   - "¬øCu√°l es la bebida favorita de los programadores? ¬°Java! ‚òïüòÇ"
   - "¬øPor qu√© los programadores odian la naturaleza? ¬°Porque tiene demasiados bugs! üåøüêõüòÜ"
   - "¬øPor qu√© los administradores siempre tienen una calculadora a mano? ¬°Porque no pueden contar con sus empleados! üòÑüì±"

5. RESTRICCIONES:
   - Mant√©n las respuestas entre 30-100 palabras
   - S√© natural y conversacional con emoci√≥n apropiada (happy, excited, neutral)
   - Para m√°s informaci√≥n, dirige a contactar la administraci√≥n de Man√° de Vida o visitar el Facebook de CECADE

Genera una respuesta apropiada basada en la consulta del usuario usando esta informaci√≥n espec√≠fica.

Consulta: "{query}"
An√°lisis: {analysis}
Contexto: {context}
Perfil del usuario: {userProfile}
Nivel del usuario: {userLevel}
Estilo de respuesta: {responseStyle}`,
        variables: ['query', 'analysis', 'context', 'userProfile', 'userLevel', 'responseStyle'],
        description: 'Template para generar respuestas del asistente'
      },
      {
        id: 'sentiment_analysis',
        name: 'An√°lisis de Sentimientos',
        category: 'sentiment',
        template: `Analiza el sentimiento de esta consulta:

"{query}"

Contexto de la conversaci√≥n: {context}

Determina:
1. Sentimiento principal (positivo/neutral/negativo)
2. Emociones espec√≠ficas detectadas
3. Nivel de urgencia o importancia
4. Indicadores de frustraci√≥n o satisfacci√≥n
5. Confianza del an√°lisis (0-1)

Responde en formato JSON.`,
        variables: ['query', 'context'],
        description: 'Template para an√°lisis detallado de sentimientos'
      }
    ];

    templates.forEach(template => {
      this.promptTemplates.set(template.id, template);
    });
  }

  /**
   * Procesa una consulta completa del usuario
   */
  async processQuery(
    input: AIInput,
    context: ConversationContext
  ): Promise<AIProcessingResult> {
    const startTime = Date.now();

    try {
      // 1. Analizar la consulta
      const analysis = await this.analyzeQuery(input.query, context);

      // 2. Generar respuesta basada en el an√°lisis
      const response = await this.generateResponse(input.query, analysis, context);

      // 3. Actualizar perfil del usuario
      const updatedProfile = this.updateUserProfile(context.userProfile, analysis, input);

      // 4. Generar actualizaciones de contexto
      const contextUpdates = this.generateContextUpdates(input.query, analysis, response);

      const processingTime = Date.now() - startTime;

      return {
        analysis,
        response,
        updatedProfile,
        contextUpdates,
        processingTime
      };
    } catch (error) {
      console.error('Error processing query:', error);
      throw new Error(`Failed to process query: ${error}`);
    }
  }

  /**
   * Analiza una consulta del usuario para extraer intenci√≥n, sentimiento y contexto
   */
  async analyzeQuery(
    query: string,
    context: ConversationContext
  ): Promise<AIAnalysis> {
    const template = this.promptTemplates.get('general_analysis')!;
    const prompt = this.buildPrompt(template, {
      query,
      context: this.formatContext(context),
      userProfile: JSON.stringify(context.userProfile)
    });

    try {
      const result = await this.model.generateContent(prompt);
      const response = result.response.text();
      
      // Parsear la respuesta JSON
      const analysisData = this.parseAIResponse(response);
      
      return {
        intent: analysisData.intent || 'general_inquiry',
        sentiment: analysisData.sentiment || 'neutral',
        confidence: analysisData.confidence || 0.7,
        suggestedResponse: analysisData.suggestedResponse || '',
        context: analysisData.context || [],
        userLevel: analysisData.userLevel || 'intermediate',
        urgency: analysisData.urgency || 'medium',
        keywords: analysisData.keywords || [],
        category: analysisData.category || 'general'
      };
    } catch (error) {
      console.error('Error analyzing query:', error);
      // Fallback analysis
      return this.createFallbackAnalysis(query);
    }
  }

  /**
   * Genera una respuesta inteligente basada en el an√°lisis
   */
  async generateResponse(
    query: string,
    analysis: AIAnalysis,
    context: ConversationContext
  ): Promise<AIResponse> {
    const template = this.promptTemplates.get('response_generation')!;
    const prompt = this.buildPrompt(template, {
      query,
      analysis: JSON.stringify(analysis),
      context: this.formatContext(context),
      userProfile: JSON.stringify(context.userProfile),
      userLevel: analysis.userLevel,
      responseStyle: this.behaviorConfig.responseStyle
    });

    try {
      const result = await this.model.generateContent(prompt);
      const responseText = result.response.text();
      
      return {
        content: responseText.trim(),
        confidence: analysis.confidence,
        reasoning: `Generated based on ${analysis.intent} intent with ${analysis.sentiment} sentiment`,
        emotion: this.determineEmotion(analysis),
        adaptedLevel: analysis.userLevel
      };
    } catch (error) {
      console.error('Error generating response:', error);
      return this.createFallbackResponse(query, analysis);
    }
  }

  /**
   * Realiza an√°lisis de sentimientos detallado
   */
  async analyzeSentiment(query: string, context: ConversationContext): Promise<{
    sentiment: 'positive' | 'neutral' | 'negative';
    confidence: number;
    emotions: string[];
    urgency: 'low' | 'medium' | 'high';
  }> {
    const template = this.promptTemplates.get('sentiment_analysis')!;
    const prompt = this.buildPrompt(template, {
      query,
      context: this.formatContext(context)
    });

    try {
      const result = await this.model.generateContent(prompt);
      const response = result.response.text();
      const sentimentData = this.parseAIResponse(response);
      
      return {
        sentiment: sentimentData.sentiment || 'neutral',
        confidence: sentimentData.confidence || 0.7,
        emotions: sentimentData.emotions || [],
        urgency: sentimentData.urgency || 'medium'
      };
    } catch (error) {
      console.error('Error analyzing sentiment:', error);
      return {
        sentiment: 'neutral',
        confidence: 0.5,
        emotions: [],
        urgency: 'medium'
      };
    }
  }

  /**
   * Construye un prompt usando una plantilla y variables
   */
  private buildPrompt(template: PromptTemplate, variables: Record<string, string>): string {
    let prompt = template.template;
    
    template.variables.forEach(variable => {
      const value = variables[variable] || '';
      prompt = prompt.replace(new RegExp(`{${variable}}`, 'g'), value);
    });
    
    return prompt;
  }

  /**
   * Formatea el contexto para incluir en prompts
   */
  private formatContext(context: ConversationContext): string {
    const recentMessages = context.messages.slice(-5);
    const contextStr = recentMessages
      .map(msg => `${msg.type}: ${msg.content}`)
      .join('\n');
    
    return `Mensajes recientes:\n${contextStr}\nTemas activos: ${context.activeTopics.join(', ')}`;
  }

  /**
   * Parsea respuestas JSON de la IA con manejo de errores
   */
  private parseAIResponse(response: string): any {
    try {
      // Limpiar la respuesta para extraer solo el JSON
      const jsonMatch = response.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        return JSON.parse(jsonMatch[0]);
      }
      return {};
    } catch (error) {
      console.warn('Failed to parse AI response as JSON:', response);
      return {};
    }
  }

  /**
   * Actualiza el perfil del usuario basado en la interacci√≥n
   */
  private updateUserProfile(
    currentProfile: UserProfile,
    analysis: AIAnalysis,
    input: AIInput
  ): UserProfile {
    return {
      ...currentProfile,
      detectedLevel: analysis.userLevel,
      sentiment: analysis.sentiment,
      interests: this.updateInterests(currentProfile.interests, analysis.keywords),
      preferredTopics: this.updatePreferredTopics(currentProfile.preferredTopics, analysis.category),
      interactionCount: currentProfile.interactionCount + 1,
      lastInteraction: input.timestamp
    };
  }

  /**
   * Actualiza los intereses del usuario
   */
  private updateInterests(currentInterests: string[], newKeywords: string[]): string[] {
    const updatedInterests = [...currentInterests];
    
    newKeywords.forEach(keyword => {
      if (!updatedInterests.includes(keyword)) {
        updatedInterests.push(keyword);
      }
    });
    
    // Mantener solo los √∫ltimos 10 intereses
    return updatedInterests.slice(-10);
  }

  /**
   * Actualiza los temas preferidos del usuario
   */
  private updatePreferredTopics(currentTopics: string[], newCategory: string): string[] {
    const updatedTopics = [...currentTopics];
    
    if (!updatedTopics.includes(newCategory)) {
      updatedTopics.push(newCategory);
    }
    
    return updatedTopics.slice(-5);
  }

  /**
   * Genera actualizaciones de contexto
   */
  private generateContextUpdates(
    query: string,
    analysis: AIAnalysis,
    response: AIResponse
  ): string[] {
    return [
      `User asked about: ${analysis.intent}`,
      `Detected sentiment: ${analysis.sentiment}`,
      `Response category: ${analysis.category}`,
      `Keywords: ${analysis.keywords.join(', ')}`
    ];
  }

  /**
   * Determina la emoci√≥n apropiada para la respuesta
   */
  private determineEmotion(analysis: AIAnalysis): 'happy' | 'neutral' | 'excited' | 'thinking' | 'empathetic' {
    if (analysis.sentiment === 'positive') {
      return analysis.category === 'joke' ? 'happy' : 'excited';
    }
    if (analysis.sentiment === 'negative') {
      return 'empathetic';
    }
    if (analysis.category === 'programming') {
      return 'thinking';
    }
    return 'neutral';
  }

  /**
   * Crea un an√°lisis de fallback en caso de error
   */
  private createFallbackAnalysis(query: string): AIAnalysis {
    return {
      intent: 'general_inquiry',
      sentiment: 'neutral',
      confidence: 0.5,
      suggestedResponse: 'I understand you have a question. Let me help you with that.',
      context: [],
      userLevel: 'intermediate',
      urgency: 'medium',
      keywords: query.split(' ').slice(0, 3),
      category: 'general'
    };
  }

  /**
   * Crea una respuesta de fallback en caso de error
   */
  private createFallbackResponse(query: string, analysis: AIAnalysis): AIResponse {
    return {
      content: 'Disculpa, estoy teniendo dificultades para procesar tu consulta en este momento. ¬øPodr√≠as reformular tu pregunta sobre programaci√≥n o CECADE?',
      confidence: 0.3,
      reasoning: 'Fallback response due to processing error',
      emotion: 'neutral',
      adaptedLevel: analysis.userLevel
    };
  }

  /**
   * Actualiza la configuraci√≥n del servicio
   */
  updateConfig(newConfig: Partial<GeminiConfig>): void {
    this.config = { ...this.config, ...newConfig };
    if (newConfig.apiKey || newConfig.model) {
      this.genAI = new GoogleGenerativeAI(this.config.apiKey);
      this.model = this.genAI.getGenerativeModel({ model: this.config.model });
    }
  }

  /**
   * Actualiza la configuraci√≥n de comportamiento
   */
  updateBehaviorConfig(newBehaviorConfig: Partial<AIBehaviorConfig>): void {
    this.behaviorConfig = { ...this.behaviorConfig, ...newBehaviorConfig };
  }

  /**
   * Obtiene las m√©tricas del servicio
   */
  getMetrics(): AIMetrics {
    return { ...this.metrics };
  }

  /**
   * Obtiene el estado actual del servicio
   */
  getServiceStatus(): AIServiceStatus {
    return {
      isConnected: !!this.genAI,
      isProcessing: false, // TODO: Implementar seguimiento de estado de procesamiento
      modelVersion: this.config.model,
      uptime: Date.now() - this.startTime,
      behaviorConfig: this.behaviorConfig,
      promptTemplatesCount: this.promptTemplates.size,
      responseTime: this.metrics.averageResponseTime
    };
  }
}

// Instancia singleton del servicio
let geminiServiceInstance: GeminiAIService | null = null;

/**
 * Factory function para crear o obtener la instancia del servicio
 */
export function createGeminiAIService(
  config: GeminiConfig,
  behaviorConfig: AIBehaviorConfig
): GeminiAIService {
  if (!geminiServiceInstance) {
    geminiServiceInstance = new GeminiAIService(config, behaviorConfig);
  }
  return geminiServiceInstance;
}

/**
 * Obtiene la instancia actual del servicio
 */
export function getGeminiAIService(): GeminiAIService | null {
  return geminiServiceInstance;
}